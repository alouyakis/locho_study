---
title: "locho_study"
date: 2025.01.31
author: 
 - Matt Jackson
 - Dayakar Badri
 - Artemis S. Louyakis
output: html_notebook
---

Study included 35 dogs each fed an identical pre-feed diet for 27 days (P-27), followed by feeding either a high protein diet or a high fat diet for ~35 days (T-34), then switched to the opposite diet for ~35 days (T-69).

Load packages used in the analysis
```{r load packages}
Sys.time()

library(tidyr)
library(tidyverse)
library(edgeR)
library(trinotateR)
library(DESeq2)
library(DEGreport)
library(NOISeq)
library(manhattanly)
library(cowplot)
library(wesanderson)
library(vegan)
library(corrplot)
library(ggtern)
library(pheatmap)

## network
library(phyloseq)
# library(dplyr)
library(plyr)
library(ggthemes)
# library(tidyr)
library(KEGGREST)
# library(tibble)
# library(ggplot2)
library(ggpubr)

# library(EnhancedVolcano) ## load separately - conflict in list
# library(beepr) ## alarm added to code chunks that may take longer than others
```

Create directories for input data and output files
```{r create dirs}
Sys.time()

data_dir <- "data"
plots_dir <- "plots"
tables_dir <- "tables"
noiseq_dir <- "noiseq"

if (!dir.exists(data_dir)) {
  dir.create(data_dir)
}
if (!dir.exists(tables_dir)) {
  dir.create(tables_dir)
}
if (!dir.exists(plots_dir)) {
  dir.create(plots_dir)
}
if (!dir.exists(noiseq_dir)) {
  dir.create(noiseq_dir)
}
if (!dir.exists(noiseq_dir)) {
  dir.create(noiseq_dir)
}
```

import counts and remove zeroes
```{r import counts data}
Sys.time()

## rsem count estimates
counts <- read.delim("alignments/iso.counts.matrix", row.names = 1)
counts <- counts[rowSums(counts) > 0,]

## normalize by gene length and transformed to counts per million
tpm <- read.delim("alignments/iso.TPM.not_cross_norm", row.names = 1)
tpm <- tpm[rowSums(tpm) > 0,]

## tmm normalized counts
# tmm <- read.delim("alignments/iso.TMM.EXPR.matrix", row.names = 1)
# tmm <- tmm[rowSums(tmm) > 0,]

count_totals <- as.data.frame(colSums(counts))
write.table(count_totals, "tables/seq_counts/count_totals.csv", quote = FALSE, col.names = FALSE)
```

one sample - F-50179103 - was mistakingly sequenced
```{r remove sample}
Sys.time()

counts <- counts %>%
  select(-mrna_F.50179103.003S)
tpm <- tpm %>%
  select(-mrna_F.50179103.003S)
```


import annotations and mapping files
```{r import annotations}
Sys.time()

## gene lengths were pulled from one of the trinity alignment results files
## awk -F"\t" '{OFS="\t"}{print $1,$3}' alignments/mrna_F-50179058-003S/mrna_F-50179058-003S.isoforms.results > data/isoform_length.txt
# len <- read.delim("data/gene_length.txt")
len <- read.delim("data/isoform_length.txt")

## trinotate annotations cutoff - 10e-3
trinotate <- read.delim("annotations/trinotate_annotation_report.xls", header = TRUE)

## maps for uniprot, kegg
uniprot_map <- read.delim("/data/databases/uniprot/uniprotkb_AND_reviewed_true_2025_03_04.tsv", header = TRUE)
## kegg org:gene to uniprot map from kegg ftp
kegg2entry <- read.delim("/data/databases/kegg/ftp.pathway.jp/kegg/genes/links/genes_uniprot.list", 
                         header = FALSE, col.names = c("Kegg", "Entry"))
## kegg org:gene to KO id from kegg ftp
kegg2ko <- read.delim("/data/databases/kegg/ftp.pathway.jp/kegg/genes/links/genes_ko.list", 
                      header = FALSE, col.names = c("Kegg", "ko"))
## housekeeping for maps
## kegg org:gene id to uniprot Entry id
kegg2entry %>% 
  mutate(Entry = gsub("up:", "", Entry)) -> kegg2entry
## kegg org:gene id to ko id
kegg2ko %>% 
  mutate(ko = gsub("ko:", "", ko)) -> kegg2ko
## uniprot Entry.Name mapped to uniprot Entry
# uniprot_map[,c("Entry", "Entry.Name")] %>% head()

## old version pulled from kegg website
# khier <- read.delim("/data/databases/kegg/khier_ko.txt", header = FALSE) %>% 
#   dplyr::rename(level1 = V1, level2 = V2, level3 = V3, ko = V4, ko_name = V5) %>% 
#   unique()
```

```{r make khier}
Sys.time()

# Read the file
lines <- readLines("/data/databases/kegg/ftp.pathway.jp/kegg/brite/ko/ko00001.keg")

# Initialize variables to keep track of current A, B, and C values
current_A <- NA
current_B <- NA
current_C <- NA

# Create an empty list to store the rows of the table
table_rows <- list()

# Iterate over each line in the file
for (line in lines) {
  # Extract the first character to decide the type of the line
  first_char <- substr(line, 1, 1)
  
  if (first_char == "A") {
    # Extract everything after "A", preserving leading zeros
    current_A <- substr(line, 2, nchar(line))
    current_A <- trimws(current_A)
  } else if (first_char == "B") {
    # Remove the prefix "B" and leading white space
    current_B <- trimws(substr(line, 3, nchar(line)))
  } else if (first_char == "C") {
    # Remove the prefix "C" and leading white space
    current_C <- trimws(substr(line, 3, nchar(line)))
  } else if (first_char == "D") {
    # Split the content after "D" to extract KO and KO Name
    content <- trimws(substr(line, 3, nchar(line)))
    ko_split <- strsplit(content, "\\s+", fixed = FALSE, perl = TRUE, useBytes = FALSE)[[1]]
    ko <- ko_split[1]
    ko_name <- paste(ko_split[-1], collapse = " ")

    # Append a new row to the table with cleaned values
    table_rows <- append(table_rows, list(c(current_A, current_B, current_C, ko, ko_name)))
  }
}

# Convert the list of rows to a data frame
khier <- data.frame(do.call(rbind, table_rows))
colnames(khier) <- c("level1", "level2", "level3", "ko", "ko_name")

write.table(khier, "/data/databases/kegg/khier.txt", quote = FALSE, row.names = FALSE)

rm(lines, current_A, current_B, current_C, table_rows, line, first_char, content, ko_split, ko, ko_name)
```

import sample metadata
```{r metadata}
Sys.time()

## metadata is for the companion metagenome
## need to use mapping file to link mt ids to mg metadata
mg_metadata <- read.delim("data/mg_metadata.csv") %>%
  rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) %>%
  mutate(mg = sub("^([^-]*-[^-]*).*", "\\1", metagenomics_sample_number))

mt_metadata <- read.delim("data/mt_sample_data.txt") %>%
  rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) %>%
  mutate(mt = sub("^([^-]*-[^-]*).*", "\\1", sample_number)) %>%
  filter(mt != "F-50179103") ## MONSTER only sampled for single time point

mgmt_map <- read.delim("data/bb4_mtmg_map.tsv") %>%
  dplyr::rename(mt_full = X.mt, mg_full = mg) %>%
  mutate(mg = sub("^([^-]*-[^-]*).*", "\\1", mg_full),
         mt = sub("^([^-]*-[^-]*).*", "\\1", mt_full)) %>%
  filter(mt != "F-50179103")

# sample_data <- read.delim("data/locho_105536_sample_data.tsv")
# results_data <- read.delim("data/locho_105536_results_data.tsv")

metadata <- merge(mg_metadata, mgmt_map, by = "mg", all = TRUE) %>%
  merge(., mt_metadata, by = "mt", all = TRUE) %>%
  mutate(mt_id = sub("-", ".", paste0("mrna_", mt, ".003S"))) %>% ## to match counts table ids
  mutate(sample_id = sub("-", ".", paste0("mrna_", mt, ".003S"))) %>%
  relocate(sample_id, .before = everything()) %>%
  mutate(treatment = paste0(time_point, "_", diet_name))
```

rsem estimates are already length corrected, so only need this for counts tables created using other methods
```{r gene length normalization}
Sys.time()

## filter gene lengths table to remove any not in counts table
len <- len[match(rownames(counts), len$transcript_id, nomatch=0),]

## normalize to gene length - 
# rpk <- counts %>%
#   merge(., len, by.x = 0, by.y = "transcript_id") %>% 
#   column_to_rownames("Row.names") %>%
#   # mutate_each(funs(./(length/1000)), starts_with("mrna")) %>% 
#   mutate(across(c(where(is.numeric), -length), ~ ./(length/1000))) %>%
#   select(-length)
```

filter annotations to get best hits for blastx and blastp
step 1: if no hit for blastx or blastp, remove
step 2: if blastx has a hit, use that first (blastx pre-filtered for best hit)
step 3: if blastx has no hit and blastp has a hit, filter for best blastp hit
step 4: combine blastx with filtered blastp

```{r make uniprot best hits map}
Sys.time()

trinotate_x <- trinotate %>% 
  filter(sprot_Top_BLASTX_hit != ".") %>%
  select(transcript_id, sprot_Top_BLASTX_hit) %>%
  distinct() %>%
  separate(sprot_Top_BLASTX_hit, into = c("uniprot"), sep = "\\^", extra = "drop", remove = FALSE, fill = "right") %>%
  separate(uniprot, into = c(NA, "entry", "entry_name"), sep = "\\|", extra = "drop", remove = FALSE, fill = "right") %>%
  select(transcript_id, entry, entry_name)

tmp <- trinotate %>%
  filter(sprot_Top_BLASTX_hit == "." & sprot_Top_BLASTP_hit != ".")

trinotate_p <- trinotate %>%
  filter(sprot_Top_BLASTX_hit == "." & sprot_Top_BLASTP_hit != ".") %>%
  select(transcript_id, sprot_Top_BLASTP_hit) %>%
  distinct() %>%
  separate(sprot_Top_BLASTP_hit, into = c("uniprot", NA, NA, NA, "evalue"),
           sep = "\\^", extra = "drop", remove = FALSE, fill = "right") %>%
  mutate(evalue = as.numeric(str_replace(evalue, 'E:', ''))) %>%
  separate(uniprot, into = c(NA, "entry", "entry_name"), sep = "\\|", extra = "drop", remove = FALSE, fill = "right") %>%
  select(transcript_id, entry, entry_name, evalue) %>%
  group_by(transcript_id) %>%
  arrange(evalue) %>%
  slice_head(n = 1) %>%
  anti_join(., trinotate_x, by = "transcript_id") %>%
  select(transcript_id, entry, entry_name)

trinotate_up <- bind_rows(trinotate_x, trinotate_p) %>%
  distinct() %>%
  group_by(transcript_id) %>%
  slice_head(n = 1) %>%
  ungroup()

# trinotate_up_all <- bind_rows(trinotate_x, trinotate_p) %>%
#   distinct() %>%
#   group_by(transcript_id) %>%
#   ungroup()

rm(trinotate_x, trinotate_p, tmp)

### old method:
## create uniprot map from trinotate annotation table
# trinotate_up <- trinotate %>% 
#   select(transcript_id, sprot_Top_BLASTX_hit, sprot_Top_BLASTP_hit) %>%
#   separate(sprot_Top_BLASTX_hit, into = c("uniprot"), sep = "\\^", extra = "drop", remove = FALSE, fill = "right") %>%
#   separate(sprot_Top_BLASTP_hit, into = c("uniprotp"), sep = "\\^", extra = "drop", remove = FALSE, fill = "right") %>%
#   mutate(uniprot = str_replace(uniprot, '\\.', '')) %>%
#   mutate(uniprotp = str_replace(uniprotp, '\\.', '')) %>%
#   mutate(uniprot = ifelse(uniprot %in% "", uniprotp, uniprot)) %>%
#   separate(uniprot, into = c(NA, "entry", "entry_name"), sep = "\\|", extra = "drop", remove = FALSE, fill = "right") %>%
#   filter(entry!="") %>%
#   select(transcript_id, entry, entry_name) %>%
#   distinct()
```

```{r run checks on trinotate}
Sys.time()

trinotate %>%
  select(X.gene_id) %>%
  unique() %>%
  nrow() -> ag
cat("Total # of genes:", ag, "\n")

trinotate %>%
  select(transcript_id) %>%
  unique() %>%
  nrow() -> ai
cat("Total # of isoforms:", ai, "\n")

trinotate %>%
  select(prot_id) %>%
  unique() %>%
  nrow() -> ap
cat("Total # of proteins:", ap, "\n")

trinotate %>% 
  filter(sprot_Top_BLASTX_hit != "." | sprot_Top_BLASTP_hit != ".") %>% 
  nrow() -> b
cat("Total # with blastx or blastp hit:", b, "\n")

trinotate %>% 
  filter(sprot_Top_BLASTX_hit == "." & sprot_Top_BLASTP_hit == ".") %>%
  nrow() -> c
cat("Total # with no blast hit:", c, "\n")

trinotate %>% 
  filter(sprot_Top_BLASTX_hit != "." & sprot_Top_BLASTP_hit != ".") %>%
  nrow() -> d
cat("Total # with both blastx and blastp hit:", d, "\n")

trinotate %>% 
  filter(sprot_Top_BLASTX_hit != "." & sprot_Top_BLASTP_hit == ".") %>%
  nrow() -> e
cat("Total # with only blastx hit:", e, "\n")

trinotate %>% 
  filter(sprot_Top_BLASTX_hit == "." & sprot_Top_BLASTP_hit != ".") %>%
  nrow() -> f
cat("Total # with only blastp hit:", f, "\n")

x <- read_trinotate("annotations/trinotate_annotation_report.xls")
summary_trinotate(x)

rm(ag, ai, ap, b, c, d, e, f, x)
```

sum by function
```{r aggregate counts by up}
Sys.time()

## merge counts with uniprot
counts_up <- merge(trinotate_up, counts, by.x = "transcript_id", by.y = "row.names") %>%
  select(!c(entry_name, transcript_id)) %>%
  group_by(entry) %>%
  dplyr::summarise(across(where(is.numeric), ~ sum(.x, na.rm = TRUE))) %>%
  column_to_rownames(var = "entry")
write.table(counts_up, "tables/rsem_uniprot.csv", quote = FALSE, row.names = TRUE)

tpm_up <- merge(trinotate_up, tpm, by.x = "transcript_id", by.y = "row.names") %>%
  select(!c(entry_name, transcript_id)) %>%
  group_by(entry) %>%
  dplyr::summarise(across(where(is.numeric), ~ sum(.x, na.rm = TRUE))) %>%
  column_to_rownames(var = "entry")
write.table(tpm_up, "tables/tpm_uniprot.csv", quote = FALSE, row.names = TRUE)

# rpk_up <- merge(trinotate_up, rpk, by.x = "transcript_id", by.y = "row.names") %>%
#   select(!c(entry_name, transcript_id)) %>%
#   group_by(entry) %>%
#   dplyr::summarise(across(where(is.numeric), ~ sum(.x, na.rm = TRUE))) %>%
#   column_to_rownames(var = "entry")

## get counts by sample for uniprot annotated 
track_counts <- merge(data.frame(colSums(counts_up)), data.frame(colSums(tpm_up)), by = "row.names") #%>%
  # merge(., data.frame(colSums(rpk_up)), by.x = "Row.names", by.y = "row.names")
```

```{r aggregate counts by kegg}
Sys.time() 

counts_ko <- counts_up %>%
  merge(., kegg2entry, by.x = 0, by.y = "Entry") %>%
  merge(., kegg2ko, by = "Kegg") %>% 
  select(!c(Row.names, Kegg)) %>%
  drop_na(ko) %>%
  group_by(ko) %>%
  dplyr::summarise(across(everything(), sum)) %>%
  column_to_rownames("ko")
write.table(counts_ko, "tables/rsem_ko.csv", quote = FALSE, row.names = TRUE)

tpm_ko <- tpm_up %>%
  merge(., kegg2entry, by.x = 0, by.y = "Entry") %>%
  merge(., kegg2ko, by = "Kegg") %>% 
  select(!c(Row.names, Kegg)) %>%
  drop_na(ko) %>%
  group_by(ko) %>%
  dplyr::summarise(across(everything(), sum)) %>%
  column_to_rownames("ko")
write.table(tpm_ko, "tables/tpm_ko.csv", quote = FALSE, row.names = TRUE)

# rpk_ko <- rpk_up %>%
#   merge(., kegg2entry, by.x = 0, by.y = "Entry") %>%
#   merge(., kegg2ko, by = "Kegg") %>%
#   select(!c(Row.names, Kegg)) %>%
#   drop_na(ko) %>%
#   group_by(ko) %>%
#   dplyr::summarise(across(everything(), sum)) %>%
#   column_to_rownames("ko")

## get counts by sample for uniprot annotated 
track_counts <- merge(track_counts, data.frame(colSums(counts_ko)), by.x = "Row.names", by.y = "row.names") %>%
  # merge(., data.frame(colSums(rpk_ko)), by.x = "Row.names", by = "row.names") %>%
  merge(., data.frame(colSums(tpm_ko)), by.x = "Row.names", by.y = "row.names")
```

after finishing functional aggregations, write a completed tracking tables
```{r write tracking table}
Sys.time()

write.csv(track_counts, "tables/seq_counts/functional_counts.csv", quote = FALSE, row.names = FALSE)
```


## cluster
```{r clustering}
Sys.time()

## clustering method suggested by Pariksheet
# https://hbctraining.github.io/DGE_workshop/lessons/08_DGE_LRT.html

count_data <- round(counts_ko, 0)
# count_data <- count_data[rowSums(count_data) > 10,]
dds <- DESeqDataSetFromMatrix(countData = count_data, colData = metadata, design = ~ treatment)
# Wald test
# dds_wald <- DESeq(dds, test="Wald")

# Likelihood ratio test
dds_lrt <- DESeq(dds, test="LRT", reduced = ~ 1)
# Extract results
res_LRT <- results(dds_lrt)

# Subset the LRT results to return genes with padj < 0.05 or pvalue < 0.05 (to plot all, pvalue<=1.0)
sig_res_LRT <- res_LRT %>%
               data.frame() %>%
               rownames_to_column(var = "gene") %>% 
               as_tibble() %>% 
               filter(pvalue <= 0.05)

# Get sig gene lists
sigLRT_genes <- sig_res_LRT %>% 
                pull(gene)
                
length(sigLRT_genes)

# Subset results for faster cluster finding (for classroom demo purposes)
# clustering_sig_genes <- sig_res_LRT %>%
#                   arrange(pvalue) %>%
#                   head(n=1000)

# Transform counts for data visualization
# rld <- rlog(dds, blind=TRUE)
# vst <- vst(dds, blind = TRUE) ## faster transformation to try 2024.07.02
vst <- varianceStabilizingTransformation(dds, blind = TRUE) 

# Plot PCA 
pca <- plotPCA(vst, intgroup = "treatment")
pca + theme_bw()
ggsave("plots/clustering/pca_rsem.png")

# Extract the rlog matrix from the object
vst_mat <- assay(vst)

# Compute pairwise correlation values
vst_cor <- cor(vst_mat)

# Plot heatmap
pheatmap(vst_cor, cellheight = 10, cellwidth = 10, filename = "plots/clustering/heatmap_rsem.png")

# Obtain rlog values for those significant genes
# cluster_rlog <- rld_mat[clustering_sig_genes$gene, ]

# Use the `degPatterns` function from the 'DEGreport' package to show gene clusters across sample groups
# clusters <- degPatterns(cluster_rlog, metadata = metadata, time = "time_food", col = NULL, minc = 1)

## cluster all genes instead of the top 1000
metadata2 <- metadata %>%
  column_to_rownames(var = "mt_id")
cluster_vst_all <- vst_mat[sig_res_LRT$gene, ]
cluster_all <- degPatterns(cluster_vst_all, metadata = metadata2, time = "time_point", col = "diet_name", minc = 1)

#### ggplot manually
###### reorder treatments
plot_data <- data.frame(cluster_all$plot$data)
plot_data$treatment <- factor(plot_data$treatment,
                    levels=c("Prefeed_HiCHO", "T1_LoCHO_PROT", "T2_LoCHO_PROT", "T1_LoCHO_FAT", "T2_LoCHO_FAT"))
# ggplot(cluster_all$plot$data) +
ggplot(plot_data) +
  geom_line(aes(x = treatment, y = value, group = genes), color = "grey") +
  geom_point(position = "jitter", aes(x = treatment, y = value, 
                                    alpha = 0.2, color = diet_name
                                    )) +
  geom_boxplot(aes(x = treatment, y = value, color = diet_name,
                   alpha = 0.2
                   )) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  theme(legend.position = "none") +
  labs(x = NULL, y = "scaled expression", title = "Clustered Kegg Orthologs") +
  theme(text = element_text(size=14), axis.text.x = element_text(size  = 14, angle = 90, hjust = 1, vjust = 1)) +
  theme(plot.title = element_text(size = 16)) +
  facet_wrap(~title, ncol = 7)
# ggsave("plots/cluster.pdf", height = 20, width = 14)
ggplot2::ggsave("plots/clustering/clusters_p0.05_rsem.png", height = 10, width = 14, create.dir = TRUE)
# ggplot2::ggsave("plots/clustering/clusters_p1.0_rsem.png", height = 8, width = 14, create.dir = TRUE)

# extract the group 3 genes
# cluster_groups <- cluster_all$df
# group3 <- cluster_all$df %>%
#             filter(cluster == 3)

dfs <- split(cluster_all$df, cluster_all$df$cluster) # list of dfs
# use numbers as file names
lapply(names(dfs),
       function(x){write.csv(dfs[[x]], paste0("tables/clusters/cluster_kegg_p0.05_rsem_", x,".csv"),
       # function(x){write.csv(dfs[[x]], paste0("tables/clusters/cluster_kegg_p1.0_rsem_", x,".csv"),
                             row.names = FALSE)})
```

```{r differential expression - ko}
Sys.time()

## test features from metadata
treatment <- unique(metadata$treatment)

## cpm normalization
ko_cpm <- cpm(counts_ko)

## create noiseq object
dds <- NOISeq::readData(data = ko_cpm, factors = metadata)
save(dds, file ="noiseq/dds_ko.RData")

## run de on treatments
for(s1 in treatment){
  for(s2 in treatment){
    if(s1!=s2){
      if(s1<s2){
        print(c(s1,s2))
        tmm <- noiseqbio(dds, norm = "tmm", k = 0.5, factor = "treatment", conditions = c(s1, s2), 
                             r = 50, filter = 0, a0per= 0.9, nclust = 15, random.seed = 321, plot = TRUE, lc = 0)
        save(tmm, file = paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm.RData"))
        tmm_r <- as.data.frame(tmm@results)
        write.table(tmm@results, paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm.txt"), sep = "\t",
                    row.names = TRUE, col.names = NA, quote = FALSE)
        tmm_r <- na.omit(tmm_r)
        tmm_r$P <- with(tmm_r, 1-prob)
        tmm_r$id <- row.names(tmm_r)
        write.table(tmm_r, paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm_filtered.txt"), sep = "\t",
                    row.names = TRUE, col.names = NA, quote = FALSE)
        tmm.deg <- list(all = degenes(tmm, q = 0.95, M = NULL),
                        up = degenes(tmm, q = 0.95, M = "up"),
                        down = degenes(tmm, q = 0.95, M = "down"))
        write.table(tmm.deg$all, paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm_deg.txt"), sep = "\t",
                    row.names = TRUE, col.names = NA, quote = FALSE)
        write.table(tmm.deg$down, paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm_deg_down.txt"), sep = "\t",
            row.names = TRUE, col.names = NA, quote = FALSE)
        write.table(tmm.deg$up, paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm_deg_up.txt"), sep = "\t",
            row.names = TRUE, col.names = NA, quote = FALSE)
      }}}}
```

```{r md plots for ko}
Sys.time()

## test features from metadata
treatment <- unique(metadata$treatment)

for(s1 in treatment){
  for(s2 in treatment){
    if(s1!=s2){
      if(s1<s2){
        print(c(s1,s2))
        load(paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm.RData"))
        DE.plot(tmm, graphic = "MD")
        tmm_r <- as.data.frame(tmm@results)
        ## plot with ggplot - 
        tmp <- data.frame(log2FC = tmm_r[,5], log_c = log(tmm_r[,1]), log_s = log(tmm_r[,2]))
        tmp$abs_mean_diff <- rowMeans(tmp[,c("log_c", "log_s")])
        ggplot(tmp, aes(x = log2FC, y = abs_mean_diff)) +
          geom_point() +
          theme_bw() + theme(panel.grid = element_blank()) +
          labs(x = expression("Log"["2"]*"FC"),
            y = "Absolute value of difference of means",
            title = paste("MD plot (ko):",s1,"vs",s2))
        ggsave(paste0("plots/md_",s1,"_vs_",s2,"_ko.png"))
        tmm_r
      }}}}
```

```{r interactive volcano - ko}
Sys.time()

## test features from metadata
treatment <- unique(metadata$treatment)

## treatment by ko - noiseq
for(s1 in treatment){
  for(s2 in treatment){
    if(s1!=s2){
      if(s1<s2){
        print(c(s1,s2))
        tmm_r <- read.delim(paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm_filtered.txt"), 
                            header=TRUE, row.names = 1, com = '', check.names = FALSE)
        tmm_rm <- merge(tmm_r, khier, by.x = "id", by.y = "ko", all.x = TRUE)
        tmm_rm$EFFECTSIZE <- tmm_rm$log2FC
        write.table(tmm_rm, paste0("noiseq/nsb_ko_",s1,"_vs_",s2,"_tmm_filtered_annot.txt"), 
                    sep = "\t", row.names = FALSE, quote = FALSE)
        volc_obj <- volcanor(tmm_rm, p = "P", effect_size = "EFFECTSIZE", snp = "id", 
                             gene = "ko_name", annotation1 = "level2", annotation2 = "level3")
        volc_plot <- volcanoly(volc_obj, effect_size_line = c(-2,2), effect_size_line_color = "orange",
                               genomewideline = -log10(1e-2), genomewideline_color = "green", title = paste(s1,"vs",s2))
        print(volc_plot)
        htmlwidgets::saveWidget(volc_plot, paste0("plots/volcano_ko_nsb_",s1,"_vs_",s2,"_tmm_filtered.html"))
      }}}}
```

network analysis
```{r network prep}
Sys.time()

## tmm adjustment to counts
tmm_ko <- NOISeq::tmm(counts_ko, long = 1000, lc = 0)
tmm_ko <- tmm_ko[rowSums(tmm_ko) > 0,]

## subset khier table
khier_sub <- khier %>%
  filter(ko %in% rownames(tmm_ko)) %>%
  group_by(ko) %>%
  slice_head() %>%
  column_to_rownames(var = "ko")

## filter pathways for network
# khier_sub <- khier %>%
#   separate(level2, c('l2id', 'level2'), sep = 5) %>%
#   # filter(level2 == 'Cellular community - prokaryotes')
#   filter(level2 == 'Energy metabolism')
## subset tmm table for subsetted khier
# tmm_ko_sub <- tmm_ko %>%
#   rownames_to_column(var = ko) %>%
#   filter(ko %in% khier_sub$ko) %>%
#   column_to_rownames(var = "ko")

## create phyloseq object
physeq <- phyloseq(otu_table(tmm_ko, taxa_are_rows = TRUE),
                   sample_data(metadata %>% column_to_rownames(var = "sample_id")),
                   tax_table(as.matrix(khier_sub)))

## create directory for plots
network_plots <- "plots/network"
if (!dir.exists(network_plots)) {
  dir.create(network_plots)
}

## graph all 
ig <- make_network(physeq, type="taxa", distance="bray", max.dist = 0.8, keep.isolates=FALSE)
```

```{r network plot}
Sys.time()

## plot the network and save the basic plot without a legend
## you can change the color to whichever factor you would like to color your nodes and edges by
plot <- plot_network(ig, physeq, type = 'taxa', color = 'level2', label = NULL,
                     line_alpha = 0.1, point_size = 1, line_weight = 0.1) +
        theme(legend.position = "none")
plot
ggsave(paste0(network_plots, "all_level2_dist0.8.png"))

# label all points
plot + geom_text(aes_string(label="value"), size = 2, hjust=1.35, na.rm=TRUE)
ggsave(paste0(network_plots, "all_level2_dist0.8_labeled.png"))

## make with legends
plot_network(ig, physeq, type = 'taxa', color = 'level2', label = NULL,
             line_alpha = 0.1, point_size = 1, line_weight = 0.1)
ggsave(paste0(network_plots, "all_level2_dist0.8_wlegend.png"))
```

```{r network filter and plot}
Sys.time()

physeq_sub <- physeq %>% 
  subset_taxa(level2 == "09102 Energy metabolism") %>%
  subset_taxa(level3 != "00195 Photosynthesis [PATH:ko00195]") %>%
  subset_taxa(level3 != "00196 Photosynthesis - antenna proteins [PATH:ko00196]")

## graph subset
ig <- make_network(physeq_sub, type = "taxa", distance = "bray", max.dist = 0.8, keep.isolates = FALSE)


```


## plotting quality not needed if running fastqc
```{r plot quality}
Sys.time()

qual <- read.delim("quality/fastx_F-50179071-003S_r1_stats.csv", header = TRUE)

ggplot(qual, aes(x = column, group = column)) +
  theme_bw() +
  geom_boxplot(stat = "identity", color="darkgrey", fill="lightgrey", alpha=0.2, 
    aes(lower = Q1, 
        upper = Q3,
        middle = mean,
        ymin = min,
        ymax = max)) 

ggplot(qual, aes(x = column, y = mean)) +
  theme_bw() +
  geom_line(color = "red") +
  scale_x_continuous(breaks = seq(0, 151, by = 10)) +
  scale_y_continuous(breaks = seq(0, 40, len = 5))
```

## filter blast data by coordinates
```{r filter blast}
Sys.time()

library(GenomicRanges)
library(plyranges)

blast_rslt <- read.table("annotations/blastx.outfmt6", header = FALSE, sep = "\t")

colnames(blast_rslt) <- c("query", "sseqid", "pident", "length", "mismatch", "gapopen", 
                          "qstart", "qend", "sstart", "send", "evalue", "bitscore")

test <- blast_rslt %>% dplyr::select(query, sseqid, qstart, qend, evalue) 

test <- test %>% 
  mutate(i_start = case_when(qstart < qend ~ qstart,
                             qend < qstart ~ qend))

test <- test %>% 
  mutate(i_end = case_when(qstart < qend ~ qend,
                           qend < qstart ~ qstart))

test <- test %>% 
  mutate(strand = case_when(qstart < qend ~ "+", 
                            qend < qstart ~ "-"))

test <- test %>% 
  select(query, sseqid, i_start, i_end, evalue, strand)

colnames(test) <- c("query", "seqnames", "start", "end", "evalue", "strand")

test_irange <- test %>% 
  as_granges()

test_disjoin <- reduce(test_irange,with.revmap = TRUE)

list_revmap <- as.data.frame(mcols(test_disjoin))

filtered_data <- c()
for(i in 1:nrow(list_revmap)){
  filtered_data <- c(filtered_data, (slice(list_revmap, i) %>% 
                                       unlist(use.names=FALSE))[which.min(slice(test,  slice(list_revmap, i) %>%
                                                                                  unlist(use.names=FALSE))$evalue)])
}

best_hits <- slice(test, filtered_data)
```

## create metaphlan table at species level for arby to run through multimedia
```{r prep for multimedia}
Sys.time()

metaphlan <- readxl::read_excel("data/msystems.00452-24-s0004.xlsx")
colnames(metaphlan) <- gsub("-005S|-004S|-003S|-002S", "", colnames(metaphlan))
metaphlan <- metaphlan %>% 
  column_to_rownames("Taxonomy\\Sample ID")

# Define a function to create a table for a given taxonomic level
create_taxa_table <- function(metaphlan, level) {
  level_names <- c("domain", "phylum", "class", "order", "family", "genus", "species")
  level_index <- match(level, level_names)
  
  # Create a list of columns to remove based on the current level
  cols_to_remove <- level_names[(level_index + 1):length(level_names)]
  
  metaphlan %>%
    rownames_to_column() %>%
    separate(col = "rowname", sep = "\\|", into = level_names, fill = "right") %>%
    # Filter out rows where the next level is NA, but the current level is not NA
    filter(if (level_index < length(level_names)) is.na(get(level_names[level_index + 1])) & !is.na(get(level)) else !is.na(get(level))) %>%
    # Select the current level and the data columns
    select(all_of(c(level, setdiff(names(metaphlan), cols_to_remove)))) %>%
    # Set the current level as row names
    column_to_rownames(var = level)
}

# List of taxonomic levels
levels <- c("domain", "phylum", "class", "order", "family", "genus", "species")

# Apply the function to each level and store the results in a list
taxa_tables <- map(levels, ~create_taxa_table(metaphlan, .x))

# Set the names of the list elements to match the taxonomic levels
names(taxa_tables) <- levels

# Now you can access the phylum table using the name
species_table <- taxa_tables[["species"]]
write.csv(species_table, "tables/metaphlan_species.csv", quote = FALSE)
```




TODO: HIGH PRIORITY cluster analysis
TODO: account for repeated measure with diet as main effect and order of diet as repeated measure
TODO: WGCNA 
TODO: RLQ - which transcription factors controlling expression of each gene [Baty et al., 2013](https://pmc.ncbi.nlm.nih.gov/articles/PMC3686578/); [RLQ R tutorial](https://rfrelat.github.io/RLQ.html); [matt's google drive on rlq](https://drive.google.com/drive/folders/1BTs1d1G__SJJWVmdvMHpZJOLJmAZ16GO)

```{r session info}
Sys.time()

sessionInfo()
```


### END ###